{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216e12e9",
   "metadata": {},
   "source": [
    "### multi-classification\n",
    ": multi-nomial classification (다중 분류) : Y값의 범주가 3개 이상인 분류\n",
    "#### 활성화 함수(Activation function) 으로 softmax함수 가 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5aefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eea2730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data set :\n",
    "# x_data :  [N,4]  --> [8,4]\n",
    "x_data = [[1,2,1,1],\n",
    "          [2,1,3,2],\n",
    "          [3,1,3,4],\n",
    "          [4,1,5,5],\n",
    "          [1,7,5,5],\n",
    "          [1,2,5,6],\n",
    "          [1,6,6,6],\n",
    "          [1,7,7,7]]\n",
    "\n",
    "# y_data : [N,3] --> [8,3]\n",
    "y_data = [[0,0,1],  # [2]\n",
    "          [0,0,1],  # [2]\n",
    "          [0,0,1],  # [2]\n",
    "          [0,1,0],  # [1]\n",
    "          [0,1,0],  # [1]\n",
    "          [0,1,0],  # [1]\n",
    "          [1,0,0],  # [0]\n",
    "          [1,0,0]]  # [0]\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53333fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'weight:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[-0.18030666, -0.95028627, -0.03964049],\n",
      "       [-0.7425406 ,  1.3231523 , -0.61854804],\n",
      "       [ 0.8540664 , -0.08899953,  2.4488697 ],\n",
      "       [ 0.762508  ,  1.2659615 ,  0.9801489 ]], dtype=float32)>\n",
      "<tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0.22652863, 0.8106553 , 0.7466094 ], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 3\n",
    "# 변수 초기화 : weight, bias\n",
    "# (m,n) * (n,l) = (m,l)   : 행렬의 내적 곱셈 공식\n",
    "# (8,4) * (4,3) = (8,3)\n",
    "W = tf.Variable(tf.random.normal([4,nb_classes]),name='weight')\n",
    "b = tf.Variable(tf.random.normal([nb_classes]),name='bias')\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da57d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수(hypothesis) : H(X) = softmax(X*W + B)\n",
    "def logits(X):\n",
    "    return tf.matmul(X,W) + b\n",
    "\n",
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(logits(X))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1617bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  비용 함수 구현 방법 1: log함수를 사용하여 수식을 직접 표현\n",
    "# def cost_func():\n",
    "#     cost = tf.reduce_mean(-tf.reduce_sum(y_train*tf.math.log(hypothesis(x_train)),\n",
    "#                                          axis=1))\n",
    "#     return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058b4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  비용함수 구현 방법 2 : tf.nn.softmax_cross_entropy_with_logits() 함수 사용\n",
    "def cost_func():\n",
    "    cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits(x_train),\n",
    "                                                    labels=y_train)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ab3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율)을 0.01 로 설정하여 optimizer객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd42a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost:[ 5.9294786 ]  W: [[-0.17030679 -0.94028634 -0.04964045]\n",
      " [-0.7325406   1.3331522  -0.628548  ]\n",
      " [ 0.86406636 -0.07899956  2.4388697 ]\n",
      " [ 0.77250797  1.2759615   0.9701489 ]]  b: [0.2365285  0.8206551  0.73660946]\n",
      "1000 cost:[ 0.31467548 ]  W: [[-2.21942592e+00  5.24806201e-01  1.18725026e+00]\n",
      " [ 1.21048994e-01  2.25326256e-03 -6.37006015e-02]\n",
      " [ 2.28707361e+00  1.16509998e+00  6.74349904e-01]\n",
      " [ 1.27608597e+00  1.77689016e+00  3.76738161e-01]]  b: [-2.7187693 -1.5067683  4.317265 ]\n",
      "2000 cost:[ 0.16304705 ]  W: [[-3.7972453   1.3537484   2.2676597 ]\n",
      " [ 0.04149103  0.02373767  0.06498571]\n",
      " [ 3.5885108   1.0490662  -0.5021981 ]\n",
      " [ 1.0556884   1.8170305   0.5562784 ]]  b: [-6.115444  -1.3375343  7.16916  ]\n",
      "3000 cost:[ 0.08965954 ]  W: [[-5.2343025   2.166253    3.208689  ]\n",
      " [-0.04391025  0.06965824  0.1601942 ]\n",
      " [ 4.872835    0.69199187 -1.5755049 ]\n",
      " [ 0.73721075  2.0572217   0.7426433 ]]  b: [-9.075818  -1.3604151  9.7624235]\n",
      "4000 cost:[ 0.051186893 ]  W: [[-6.5691338   2.9417899   4.0721755 ]\n",
      " [-0.12962762  0.12063995  0.24656813]\n",
      " [ 6.118548    0.27676868 -2.5946243 ]\n",
      " [ 0.37533033  2.3316693   0.9539066 ]]  b: [-11.740836   -1.3668149  12.113419 ]\n",
      "5000 cost:[ 0.02982126 ]  W: [[-7.8441839e+00  3.6925719e+00  4.8953743e+00]\n",
      " [-2.1366459e-01  1.7167655e-01  3.2927501e-01]\n",
      " [ 7.3285408e+00 -1.4589469e-01 -3.5808372e+00]\n",
      " [-2.5778222e-03  2.6041069e+00  1.1803559e+00]]  b: [-14.224036   -1.3462137  14.310632 ]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    optimizer.minimize(cost_func,var_list=[W,b])\n",
    "    if step % 1000 == 0:\n",
    "        print('%04d'%step,'cost:[',cost_func().numpy(),']',\n",
    "             ' W:',W.numpy(),' b:',b.numpy())\n",
    "print('***** Learning Finished!!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae4b803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: [[-7.8441839e+00  3.6925719e+00  4.8953743e+00]\n",
      " [-2.1366459e-01  1.7167655e-01  3.2927501e-01]\n",
      " [ 7.3285408e+00 -1.4589469e-01 -3.5808372e+00]\n",
      " [-2.5778222e-03  2.6041069e+00  1.1803559e+00]]\n",
      "Bias: [-14.224036   -1.3462137  14.310632 ]\n"
     ]
    }
   ],
   "source": [
    "# weight과 bias 출력\n",
    "print('Weight:',W.numpy())\n",
    "print('Bias:',b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c456626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 1 1 0 0]\n",
      "[[6.7201633e-15 4.4787926e-06 9.9999547e-01]\n",
      " [3.0885534e-11 6.2573748e-03 9.9374264e-01]\n",
      " [8.2858872e-18 3.1583689e-02 9.6841633e-01]\n",
      " [5.7242741e-16 9.7510344e-01 2.4896599e-02]\n",
      " [5.8690630e-02 9.3963599e-01 1.6734080e-03]\n",
      " [3.0667992e-02 9.6914297e-01 1.8900885e-04]\n",
      " [9.2271829e-01 7.7280879e-02 9.1235961e-07]\n",
      " [9.9905401e-01 9.4603369e-04 1.0147081e-10]]\n",
      "[2 2 2 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "# tf.argmax() : 값이 가장 큰 요소의 인덱스 값을 반환\n",
    "def predict(X):\n",
    "    return tf.argmax(hypothesis(X),axis=1)\n",
    "\n",
    "# 학습 데이터를 검증 데이터로 동일하게 사용하는 경우\n",
    "x_test = x_train\n",
    "y_test = y_train\n",
    "\n",
    "preds = predict(x_test)\n",
    "print(preds.numpy())\n",
    "print(hypothesis(x_test).numpy())\n",
    "print(tf.argmax(y_test,axis=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a43499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
